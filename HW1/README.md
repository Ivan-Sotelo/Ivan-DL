The CNN with dropout and Batch normalization proved to be more accurate than the MLP archiecture 
The CNN yielded an accuracy result of 77.5% while the MLP only yielded an accuracy result of 51.1%

The results for the accuracy and loss can be seen in the figures below: 

for MLP:

<p align="center">
  <img src="Docu/MLP Accuracy.png" width="350" title="Accuracy">
  <img src="Docu/MLP loss.png" width="350" alt="Loss">
</p>

for CNN:


<p align="center">
  <img src="Docu/CNN accuracy.png" width="350" title="Accuracy">
  <img src="Docu/CNN loss.png" width="350" alt="Loss">
</p>
